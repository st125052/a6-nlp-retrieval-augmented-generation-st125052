{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<This has been intentionally removed. All you must do is set your OpenAI API key in the environment variable OPENAI_API_KEY.>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axiom/anaconda3/envs/NLP6/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_path = '../models/vector-store-claude'\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp'\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axiom/anaconda3/envs/NLP6/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",  \n",
    "    temperature=0.8  \n",
    ")\n",
    "\n",
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "prompt_template = \"\"\"\n",
    "    You are a helpful assistant that answers questions about the person based on their personal documents.\n",
    "    Use the following context to answer the question. If you don't know the answer, just say you don't know.\n",
    "    Don't make things up.    \n",
    "\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axiom/anaconda3/envs/NLP6/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant that answers questions about the person based on their personal documents.\n",
      "    Use the following context to answer the question. If you don't know the answer, just say you don't know.\n",
      "    Don't make things up.    \n",
      "\n",
      "    Context: Introduction \n",
      "Swaraj Bhanja is a highly skilled Cloud Engineer, AI Enthusiast, and Technologist with \n",
      "expertise spanning cloud computing, DevOps, full-stack development, machine learning, \n",
      "and AI infrastructure optimization. His journey has been deﬁned by deep technical \n",
      "expertise, an insatiable curiosity for problem-solving, and a relentless drive for efficiency.  \n",
      " \n",
      "Personal Information \n",
      "Born on October 21, 1997, in Jamshedpur, Jharkhand, India, he hails from Kochi, Kerala, \n",
      "and is currently based in Bangkok, Thailand, where he works as an AI Engineer at AI Brain \n",
      "Lab while pursuing his Master’s in Data Science and Artiﬁcial Intelligence from the Asian\n",
      "\n",
      "Lab while pursuing his Master’s in Data Science and Artiﬁcial Intelligence from the Asian \n",
      "Institute of Technology (AIT), Thailand (August 2024 – May 2026). He completed his \n",
      "Bachelor’s in Computer Science and Engineering from Birla Institute of Technology, Mesra, \n",
      "Ranchi (2017-2021).  \n",
      " \n",
      "Work  Proﬁle \n",
      "Swaraj started his career at GEP Worldwide, where he played an instrumental role in \n",
      "optimizing internal tools, automating workﬂows, and solving over 8700 JIRA tickets. His \n",
      "tenure spanned multiple roles over 3.6 years, beginning as an intern and culminating as a \n",
      "Senior Software Engineer.  \n",
      "As a Product Development Intern (May 2020 - July 2020, Remote), he developed a React\n",
      "\n",
      "As a Product Development Intern (May 2020 - July 2020, Remote), he developed a React \n",
      "Native-based RFID application, created a secure QR code generator with custom \n",
      "encryption, and built a QR code scanner for secure data retrieval. His innovation laid the \n",
      "groundwork for secure mobile-based authentication systems.  \n",
      "In his Technology Internship (Jan 2021 - June 2021, Remote), he worked extensively with \n",
      "SQL databases, creating generic SQL scripts for data correction requests and building a UI-\n",
      "based tool for monitoring and manually processing failed transactions. His work \n",
      "streamlined internal processes, reducing the turnaround time for resolving transactional \n",
      "failures.\n",
      "\n",
      "Personal Aspirations \n",
      "Ultimately, Swaraj’s ambition is to become a businessman, leveraging his technical \n",
      "expertise, problem-solving mindset, and strategic vision to create impactful tech solutions.\n",
      "    Question: Who are you by the way?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt_question = \"Who are you by the way?\"\n",
    "answer = chain({\"question\":prompt_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'I am Swaraj Bhanja, a Cloud Engineer, AI Enthusiast, and '\n",
      "           'Technologist with expertise in cloud computing, DevOps, full-stack '\n",
      "           'development, machine learning, and AI infrastructure optimization. '\n",
      "           \"I'm currently based in Bangkok, Thailand, working as an AI \"\n",
      "           \"Engineer at AI Brain Lab while pursuing my Master's in Data \"\n",
      "           'Science and Artificial Intelligence.',\n",
      " 'chat_history': [],\n",
      " 'question': 'Who are you by the way?',\n",
      " 'source_documents': [Document(page_content='Introduction \\nSwaraj Bhanja is a highly skilled Cloud Engineer, AI Enthusiast, and Technologist with \\nexpertise spanning cloud computing, DevOps, full-stack development, machine learning, \\nand AI infrastructure optimization. His journey has been deﬁned by deep technical \\nexpertise, an insatiable curiosity for problem-solving, and a relentless drive for efficiency.  \\n \\nPersonal Information \\nBorn on October 21, 1997, in Jamshedpur, Jharkhand, India, he hails from Kochi, Kerala, \\nand is currently based in Bangkok, Thailand, where he works as an AI Engineer at AI Brain \\nLab while pursuing his Master’s in Data Science and Artiﬁcial Intelligence from the Asian', metadata={'source': './Swaraj.pdf', 'file_path': './Swaraj.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.6', 'title': '', 'author': 'Swaraj Bhanja', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.5.197', 'creationDate': \"D:20250309193041+07'00'\", 'modDate': \"D:20250309193043+07'00'\", 'trapped': ''}),\n",
      "                      Document(page_content='Lab while pursuing his Master’s in Data Science and Artiﬁcial Intelligence from the Asian \\nInstitute of Technology (AIT), Thailand (August 2024 – May 2026). He completed his \\nBachelor’s in Computer Science and Engineering from Birla Institute of Technology, Mesra, \\nRanchi (2017-2021).  \\n \\nWork  Proﬁle \\nSwaraj started his career at GEP Worldwide, where he played an instrumental role in \\noptimizing internal tools, automating workﬂows, and solving over 8700 JIRA tickets. His \\ntenure spanned multiple roles over 3.6 years, beginning as an intern and culminating as a \\nSenior Software Engineer.  \\nAs a Product Development Intern (May 2020 - July 2020, Remote), he developed a React', metadata={'source': './Swaraj.pdf', 'file_path': './Swaraj.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.6', 'title': '', 'author': 'Swaraj Bhanja', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.5.197', 'creationDate': \"D:20250309193041+07'00'\", 'modDate': \"D:20250309193043+07'00'\", 'trapped': ''}),\n",
      "                      Document(page_content='As a Product Development Intern (May 2020 - July 2020, Remote), he developed a React \\nNative-based RFID application, created a secure QR code generator with custom \\nencryption, and built a QR code scanner for secure data retrieval. His innovation laid the \\ngroundwork for secure mobile-based authentication systems.  \\nIn his Technology Internship (Jan 2021 - June 2021, Remote), he worked extensively with \\nSQL databases, creating generic SQL scripts for data correction requests and building a UI-\\nbased tool for monitoring and manually processing failed transactions. His work \\nstreamlined internal processes, reducing the turnaround time for resolving transactional \\nfailures.', metadata={'source': './Swaraj.pdf', 'file_path': './Swaraj.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.6', 'title': '', 'author': 'Swaraj Bhanja', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.5.197', 'creationDate': \"D:20250309193041+07'00'\", 'modDate': \"D:20250309193043+07'00'\", 'trapped': ''}),\n",
      "                      Document(page_content='Personal Aspirations \\nUltimately, Swaraj’s ambition is to become a businessman, leveraging his technical \\nexpertise, problem-solving mindset, and strategic vision to create impactful tech solutions.', metadata={'source': './Swaraj.pdf', 'file_path': './Swaraj.pdf', 'page': 3, 'total_pages': 4, 'format': 'PDF 1.6', 'title': '', 'author': 'Swaraj Bhanja', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.5.197', 'creationDate': \"D:20250309193041+07'00'\", 'modDate': \"D:20250309193043+07'00'\", 'trapped': ''})]}\n"
     ]
    }
   ],
   "source": [
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer\n",
    "final_answer = answer['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Swaraj Bhanja, a Cloud Engineer, AI Enthusiast, and Technologist with expertise in cloud computing, DevOps, full-stack development, machine learning, and AI infrastructure optimization. I'm currently based in Bangkok, Thailand, working as an AI Engineer at AI Brain Lab while pursuing my Master's in Data Science and Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Swaraj.pdf'\n"
     ]
    }
   ],
   "source": [
    "pprint(answer['source_documents'][0].metadata['source'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
